# -*- coding: utf-8 -*-
import os
import yaml
import torch
import numpy as np
from PIL import Image
from datetime import datetime
import json

from ..models.sam_segmenter import SAMSegmenter
from ..models.edge_detector import EdgeDetector
from ..models.controlnet_generator import ControlNetGenerator
from ..processors.color_quantizer import ColorQuantizer
from ..processors.symmetry_maker import SymmetryMaker
from ..processors.vectorizer import Vectorizer
from ..utils.paths import DEFAULT_CONFIG_PATH, SAM_MODEL_CHECKPOINT

class ProcessingCancelledError(Exception):
    """Ø§ÛŒÙ† Ø®Ø·Ø§ Ø²Ù…Ø§Ù†ÛŒ Ú©Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù„ØºÙˆ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯."""
    pass

class CarpetDesignPipeline:
    def __init__(self, config_path=DEFAULT_CONFIG_PATH):
        print("=" * 80)
        print("ğŸ§¶ Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ ØªØ¨Ø¯ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ù‡ Ø·Ø±Ø­ ØµÙ†Ø¹ØªÛŒ ÙØ±Ø´ (Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ† Ù†Ø³Ø®Ù‡ Û².Û·)")
        print("=" * 80)
        
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # --- Ù…Ù†Ø·Ù‚ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯ÛŒØ§ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø¯Ø³ØªÚ¯Ø§Ù‡ ---
        config_device = self.config.get('models', {}).get('device', 'auto')
        if config_device == 'auto':
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = config_device
        
        print(f"ğŸ–¥ï¸  Ø¯Ø³ØªÚ¯Ø§Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯Ù‡: {self.device}")
        
        self._sam = None
        self._edge_detector = None
        self._controlnet_instances = {}
        
        self.color_quantizer = ColorQuantizer()
        self.symmetry_maker = SymmetryMaker()
        self.vectorizer = None
        self.custom_palette = None
        self.carpet_specs = None

    def _lazy_load_controlnet(self, base_model_path, controlnet_path):
        instance_key = (base_model_path, controlnet_path)
        if instance_key not in self._controlnet_instances:
            self.log_callback(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ControlNet + Stable Diffusion...")
            self.log_callback(f"   - Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡: {base_model_path}")
            self.log_callback(f"   - Ù…Ø¯Ù„ Ú©Ù†ØªØ±Ù„: {controlnet_path}")
            self.log_callback("   (Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø¨Ø³ÛŒØ§Ø± Ø²Ù…Ø§Ù†â€ŒØ¨Ø± Ø¨Ø§Ø´Ø¯ Ùˆ Ø¨Ù‡ Ø­Ø§ÙØ¸Ù‡ VRAM Ø¨Ø§Ù„Ø§ÛŒÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±Ø¯)")
            
            generator_instance = ControlNetGenerator(
                base_model=base_model_path,
                controlnet_model=controlnet_path,
                device=self.device
            )
            self._controlnet_instances[instance_key] = generator_instance
            self.log_callback(f"âœ… Ù…Ø¯Ù„ ControlNet Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return self._controlnet_instances[instance_key]

    def _lazy_load_sam(self):
        if self._sam is None:
            self.log_callback("â³ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ SAM (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù…ÛŒ Ø·ÙˆÙ„ Ø¨Ú©Ø´Ø¯)...")
            sam_model_type = self.config.get('models', {}).get('sam', {}).get('model_type', 'vit_h')
            self._sam = SAMSegmenter(
                model_type=sam_model_type,
                checkpoint_path=SAM_MODEL_CHECKPOINT,
                device=self.device
            )
            self.log_callback("âœ… Ù…Ø¯Ù„ SAM Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return self._sam

    def _lazy_load_edge_detector(self):
        if self._edge_detector is None:
            method = self.config.get('processing', {}).get('edge_detection', {}).get('method', 'HED')
            self.log_callback(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ù„Ø¨Ù‡ ({method})...")
            self._edge_detector = EdgeDetector(method=method, device=self.device)
            self.log_callback("âœ… Ù…Ø¯Ù„ ØªØ´Ø®ÛŒØµ Ù„Ø¨Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
        return self._edge_detector

    def _check_for_cancel(self, cancel_event):
        if cancel_event and cancel_event.is_set():
            raise ProcessingCancelledError("Ø¹Ù…Ù„ÛŒØ§Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù„ØºÙˆ Ø´Ø¯.")

    def _update_progress(self, current_step, total_steps, cancel_event):
        self._check_for_cancel(cancel_event)
        if self.progress_callback:
            self.progress_callback(current_step, total_steps)
            
    def process_image(self, input_image, output_dir='output', run_config=None, cancel_event=None, log_callback=print, progress_callback=None):
        self.log_callback = log_callback
        self.progress_callback = progress_callback
        
        total_steps = sum(1 for step in [
            'remove_background', 'detect_edges', 'generate_design', 
            'quantize_colors', 'apply_symmetry', 'vectorize'
        ] if run_config.get(step))
        current_step = 0
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(output_dir, timestamp)
        os.makedirs(output_path, exist_ok=True)
        self.log_callback(f"ğŸ“ Ù¾ÙˆØ´Ù‡ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø§Ø¬Ø±Ø§: {output_path}\n")
        self._check_for_cancel(cancel_event)
        image = input_image.copy()
        self.log_callback(f"ğŸ“· ØªØµÙˆÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§ Ø§Ø¨Ø¹Ø§Ø¯ {image.width}x{image.height} Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯.")
        results = {'original': image, 'output_path': output_path}
        self.log_callback("\n" + "="*40 + "\nÙ…Ø±Ø­Ù„Ù‡ Û°: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø¨Ø¹Ø§Ø¯ Ù†Ù‚Ø´Ù‡ Ú¯Ø±Ù‡\n" + "="*40)
        spec = self.carpet_specs
        width_px = int((spec['width_cm'] / 10) * spec['shaneh'])
        height_px = int((spec['height_cm'] / 10) * spec['tar'])
        self.log_callback(f"   - Ø§Ø¨Ø¹Ø§Ø¯ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÚ¯Ø§Ù‡: {width_px} x {height_px} Ù¾ÛŒÚ©Ø³Ù„ (Ú¯Ø±Ù‡)")
        image = image.resize((width_px, height_px), Image.LANCZOS)
        self.log_callback("   - ØªØµÙˆÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ù‡ Ø§Ø¨Ø¹Ø§Ø¯ Ù†Ù‚Ø´Ù‡ Ú¯Ø±Ù‡ ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ ÛŒØ§ÙØª.")
        if run_config.get('save_intermediate'):
            image.save(os.path.join(output_path, '01_knot_resolution.png'))

        processed_image = image
        if run_config.get('remove_background'):
            current_step += 1
            self.log_callback("\n" + "="*40 + f"\nÙ…Ø±Ø­Ù„Ù‡ {current_step}/{total_steps}: Ø­Ø°Ù Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¨Ø§ SAM\n" + "="*40)
            self._update_progress(current_step, total_steps, cancel_event)
            sam_model = self._lazy_load_sam()
            main_mask = sam_model.extract_main_object(image, fast_mode=run_config.get('sam_fast_mode', False))
            if main_mask is not None:
                processed_image = sam_model.apply_mask_to_image(image, main_mask)
                if run_config.get('save_intermediate'):
                    processed_image.save(os.path.join(output_path, '02_background_removed.png'))
                self.log_callback("âœ… Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø­Ø°Ù Ø´Ø¯.")
            else:
                self.log_callback("âš ï¸ Ù‡ÛŒÚ† Ø´ÛŒØ¡ ØºØ§Ù„Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø§Ø² ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

        refined_edges = None
        if run_config.get('detect_edges'):
            current_step += 1
            self.log_callback("\n" + "="*40 + f"\nÙ…Ø±Ø­Ù„Ù‡ {current_step}/{total_steps}: ØªØ´Ø®ÛŒØµ Ù„Ø¨Ù‡â€ŒÙ‡Ø§\n" + "="*40)
            self._update_progress(current_step, total_steps, cancel_event)
            edge_model = self._lazy_load_edge_detector()
            edges = edge_model.detect_edges(processed_image)
            refined_edges_np = edge_model.refine_edges(edges, kernel_size=3)
            refined_edges = Image.fromarray(refined_edges_np)
            if run_config.get('save_intermediate'):
                refined_edges.save(os.path.join(output_path, '03_edges.png'))
            self.log_callback("âœ… Ù„Ø¨Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯.")
            
        working_image = processed_image
        if run_config.get('generate_design'):
            current_step += 1
            self.log_callback("\n" + "="*40 + f"\nÙ…Ø±Ø­Ù„Ù‡ {current_step}/{total_steps}: ØªÙˆÙ„ÛŒØ¯ Ø·Ø±Ø­ ÙØ±Ø´ Ø¨Ø§ AI\n" + "="*40)
            self._update_progress(current_step, total_steps, cancel_event)
            
            base_model_path = run_config.get('base_model_path')
            controlnet_path = run_config.get('controlnet_path')

            if not base_model_path or not controlnet_path:
                self.log_callback("âŒ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ ÛŒØ§ Ù…Ø¯Ù„ Ú©Ù†ØªØ±Ù„ Ù…Ø´Ø®Øµ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")
            else:
                control_image_for_ai = None
                if 'tile' in controlnet_path.lower():
                    self.log_callback("â„¹ï¸ Ø§Ø² Ø­Ø§Ù„Øª ControlNet-Tile Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÙˆØ±ÙˆØ¯ÛŒ Ú©Ù†ØªØ±Ù„ Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯.")
                    control_image_for_ai = processed_image
                else:
                    if refined_edges:
                        control_image_for_ai = refined_edges
                    else:
                        self.log_callback("âš ï¸ ØªÛŒÚ© 'ØªØ´Ø®ÛŒØµ Ù„Ø¨Ù‡' ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª. ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø¯Ù„ Ú©Ù†ØªØ±Ù„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯. Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯.")

                if control_image_for_ai:
                    controlnet_model = self._lazy_load_controlnet(base_model_path, controlnet_path)
                    gen_config = self.config['generation']
                    enhanced_prompt = gen_config['prompts']['positive']
                    if self.carpet_specs:
                        enhanced_prompt += f", carpet design for {self.carpet_specs['width_cm']}x{self.carpet_specs['height_cm']}cm, {self.carpet_specs['shaneh']} raj density"
                    
                    output_width, output_height = width_px, height_px

                    generated_images = controlnet_model.generate(
                        control_image=control_image_for_ai,
                        prompt=enhanced_prompt,
                        negative_prompt=gen_config['prompts']['negative'],
                        num_inference_steps=gen_config['steps'],
                        guidance_scale=gen_config['guidance_scale'],
                        controlnet_conditioning_scale=gen_config['controlnet_scale'],
                        seed=gen_config['seed'] if gen_config['seed'] != -1 else None,
                        width=output_width,
                        height=output_height
                    )
                    working_image = generated_images[0]
                    if run_config.get('save_intermediate'):
                        working_image.save(os.path.join(output_path, '04_ai_generated.png'))
                    self.log_callback("âœ… Ø·Ø±Ø­ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯.")
        
        if run_config.get('quantize_colors'):
            current_step += 1
            self.log_callback("\n" + "="*40 + f"\nÙ…Ø±Ø­Ù„Ù‡ {current_step}/{total_steps}: Ú©Ø§Ù‡Ø´ Ø±Ù†Ú¯â€ŒÙ‡Ø§\n" + "="*40)
            self._update_progress(current_step, total_steps, cancel_event)
            if self.custom_palette is not None and len(self.custom_palette) > 0:
                self.log_callback(f"ğŸ¨ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø§Ù„Øª Ø±Ù†Ú¯ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ Ø¨Ø§ {len(self.custom_palette)} Ø±Ù†Ú¯.")
                quantized_image, palette = self.color_quantizer.apply_palette_with_dithering(working_image, self.custom_palette)
            else:
                n_colors = self.config['processing']['color_quantization']['n_colors']
                self.log_callback(f"ğŸ¨ Ú©ÙˆØ§Ù†ØªÛŒØ²Ù‡ Ú©Ø±Ø¯Ù† Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ù‡ {n_colors} Ø±Ù†Ú¯.")
                self.color_quantizer.n_colors = n_colors
                quantized_image, palette = self.color_quantizer.quantize_with_dithering(working_image)
            
            palette_viz = self.color_quantizer.create_palette_visualization(palette)
            
            if run_config.get('save_intermediate'):
                quantized_image.save(os.path.join(output_path, '05_quantized.png'))
                palette_viz.save(os.path.join(output_path, '05_palette.png'))
            self.save_color_info(palette, output_path)
            working_image = quantized_image
            self.log_callback("âœ… Ø±Ù†Ú¯â€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ú©Ø§Ù‡Ø´ ÛŒØ§ÙØª.")
        
        if run_config.get('apply_symmetry') and not run_config.get('is_full_design'):
            current_step += 1
            self.log_callback("\n" + "="*40 + f"\nÙ…Ø±Ø­Ù„Ù‡ {current_step}/{total_steps}: Ø§ÛŒØ¬Ø§Ø¯ ØªÙ‚Ø§Ø±Ù† Ùˆ Ú†ÛŒØ¯Ù…Ø§Ù†\n" + "="*40)
            self._update_progress(current_step, total_steps, cancel_event)
            four_way = self.symmetry_maker.create_four_way_mirror(working_image)
            if run_config.get('save_intermediate'):
                four_way.save(os.path.join(output_path, '06_four_way_symmetry.png'))
            
            background_color = tuple(self.config['output'].get('medallion_background_color', [245, 240, 230]))
            
            medallion_layout = self.symmetry_maker.create_medallion_layout(
                center_element=four_way,
                canvas_size=(width_px, height_px),
                background_color=background_color
            )
            if run_config.get('save_intermediate'):
                medallion_layout.save(os.path.join(output_path, '07_medallion_layout.png'))
            working_image = medallion_layout
            self.log_callback("âœ… ØªÙ‚Ø§Ø±Ù† Ùˆ Ú†ÛŒØ¯Ù…Ø§Ù† Ù…Ø¯Ø§Ù„ÛŒÙˆÙ† Ø§Ø¹Ù…Ø§Ù„ Ø´Ø¯.")
        elif run_config.get('is_full_design'):
             self.log_callback("\n" + "="*40 + "\nâ„¹ï¸ Ù…Ø±Ø­Ù„Ù‡ ØªÙ‚Ø§Ø±Ù† Ùˆ Ú†ÛŒØ¯Ù…Ø§Ù† Ø±Ø¯ Ø´Ø¯ (ÙˆØ±ÙˆØ¯ÛŒ ÛŒÚ© Ø·Ø±Ø­ Ú©Ø§Ù…Ù„ Ø§Ø³Øª).\n" + "="*40)

        if run_config.get('vectorize'):
            current_step += 1
            self.log_callback("\n" + "="*40 + f"\nÙ…Ø±Ø­Ù„Ù‡ {current_step}/{total_steps}: ÙˆÚ©ØªÙˆØ±ÛŒâ€ŒØ³Ø§Ø²ÛŒ\n" + "="*40)
            self._update_progress(current_step, total_steps, cancel_event)
            try:
                self.vectorizer = Vectorizer(method='vtracer')
                svg_path = os.path.join(output_path, 'final_design.svg')
                
                vector_kwargs = {
                    'filter_speckle': run_config.get('vector_speckle', 4),
                    'color_precision': run_config.get('vector_color_precision', 6),
                    'corner_threshold': run_config.get('vector_corner_threshold', 60)
                }

                svg_result = self.vectorizer.vectorize(working_image, svg_path, **vector_kwargs)
                if svg_result:
                    pdf_path = os.path.join(output_path, 'final_design.pdf')
                    self.vectorizer.svg_to_pdf(svg_path, pdf_path)
                    self.log_callback("âœ… ÙˆÚ©ØªÙˆØ±Ø³Ø§Ø²ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
            except Exception as e:
                self.log_callback(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙˆÚ©ØªÙˆØ±Ø³Ø§Ø²ÛŒ: {e}")

        final_image = working_image
        final_path = os.path.join(output_path, 'final_design.png')
        final_image.save(final_path)
        results['final_png'] = final_path
        self.log_callback(f"\nâœ… Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ù‚ÛŒÙ‚ {final_image.width}x{final_image.height} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {final_path}")

        if self.carpet_specs:
            self.save_carpet_specs(output_path)
            
        return results

    def save_color_info(self, palette, output_path):
        color_info = {
            'palette': [
                {'index': i+1, 'rgb': list(map(int, color)), 'hex': '#%02x%02x%02x' % tuple(map(int, color))}
                for i, color in enumerate(palette)
            ],
            'total_colors': len(palette)
        }
        info_path = os.path.join(output_path, 'color_info.json')
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(color_info, f, indent=4, ensure_ascii=False)
        self.log_callback(f"   - Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø±Ù†Ú¯ÛŒ Ø¯Ø± ÙØ§ÛŒÙ„ color_info.json Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

    def save_carpet_specs(self, output_path):
        if not self.carpet_specs:
            return

        density = (self.carpet_specs['shaneh'] / 10) * self.carpet_specs['tar']
        width_m = self.carpet_specs['width_cm'] / 100
        height_m = self.carpet_specs['height_cm'] / 100
        area_m2 = width_m * height_m
        total_knots = (width_m * self.carpet_specs['shaneh'] * 10) * (height_m * self.carpet_specs['tar'] * 10)
        
        specs = {
            'dimensions': { 'width_cm': self.carpet_specs['width_cm'], 'height_cm': self.carpet_specs['height_cm'], 'width_m': width_m, 'height_m': height_m },
            'weaving': { 'shaneh_per_10cm': self.carpet_specs['shaneh'], 'tar_per_10cm': self.carpet_specs['tar'], 'density_per_dm2': int(density), 'density_per_m2': int(density * 100), 'raj': self.carpet_specs['shaneh'] },
            'production_estimate': { 'area_m2': round(area_m2, 2), 'total_knots': int(total_knots) }
        }
        
        specs_path_json = os.path.join(output_path, 'carpet_specifications.json')
        with open(specs_path_json, 'w', encoding='utf-8') as f:
            json.dump(specs, f, indent=4, ensure_ascii=False)

        specs_path_txt = os.path.join(output_path, 'carpet_specifications.txt')
        with open(specs_path_txt, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\nÙ…Ø´Ø®ØµØ§Øª ÙÙ†ÛŒ ÙØ±Ø´\n" + "=" * 60 + "\n\n")
            f.write(f"Ø§Ø¨Ø¹Ø§Ø¯:\n")
            f.write(f"  - Ø¹Ø±Ø¶: {specs['dimensions']['width_cm']} Ø³Ø§Ù†ØªÛŒâ€ŒÙ…ØªØ± ({specs['dimensions']['width_m']:.2f} Ù…ØªØ±)\n")
            f.write(f"  - Ø·ÙˆÙ„: {specs['dimensions']['height_cm']} Ø³Ø§Ù†ØªÛŒâ€ŒÙ…ØªØ± ({specs['dimensions']['height_m']:.2f} Ù…ØªØ±)\n")
            f.write(f"  - Ù…Ø³Ø§Ø­Øª: {specs['production_estimate']['area_m2']:.2f} Ù…ØªØ± Ù…Ø±Ø¨Ø¹\n\n")
            f.write(f"Ø¨Ø§ÙØª:\n")
            f.write(f"  - Ø´Ø§Ù†Ù‡: {specs['weaving']['shaneh_per_10cm']} (Ú¯Ø±Ù‡ Ø¯Ø± Ø¹Ø±Ø¶ Û±Û° Ø³Ø§Ù†ØªÛŒâ€ŒÙ…ØªØ±)\n")
            f.write(f"  - ØªØ±Ø§Ú©Ù… Ø·ÙˆÙ„ÛŒ (ØªØ§Ø±): {specs['weaving']['tar_per_10cm']} (Ú¯Ø±Ù‡ Ø¯Ø± Ø·ÙˆÙ„ Û±Û° Ø³Ø§Ù†ØªÛŒâ€ŒÙ…ØªØ±)\n")
            f.write(f"  - ØªØ±Ø§Ú©Ù… Ú©Ù„: {specs['weaving']['density_per_m2']} Ú¯Ø±Ù‡ Ø¯Ø± Ù…ØªØ± Ù…Ø±Ø¨Ø¹\n\n")
            f.write(f"Ø¨Ø±Ø¢ÙˆØ±Ø¯ ØªÙˆÙ„ÛŒØ¯:\n")
            f.write(f"  - ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ú¯Ø±Ù‡â€ŒÙ‡Ø§: {specs['production_estimate']['total_knots']:,}\n")

        self.log_callback(f"   - Ù…Ø´Ø®ØµØ§Øª ÙØ±Ø´ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ JSON Ùˆ TXT Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")