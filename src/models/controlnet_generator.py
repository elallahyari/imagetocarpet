import torch
import numpy as np
from PIL import Image
from diffusers import (
    StableDiffusionControlNetPipeline,
    ControlNetModel,
    UniPCMultistepScheduler
)
from diffusers.utils import load_image

class ControlNetGenerator:
    """Ú©Ù„Ø§Ø³ ØªÙˆÙ„ÛŒØ¯ Ø·Ø±Ø­ ÙØ±Ø´ Ø¨Ø§ ControlNet"""
    
    def __init__(self, base_model, controlnet_model, device="cuda", dtype=torch.float16):
        self.device = device
        self.dtype = dtype
        
        print(f"ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ControlNet...")
        print(f"   Base Model: {base_model}")
        print(f"   ControlNet: {controlnet_model}")
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ControlNet
        self.controlnet = ControlNetModel.from_pretrained(
            controlnet_model,
            torch_dtype=dtype
        )
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù¾Ø§ÛŒÙ¾Ù„Ø§ÛŒÙ†
        self.pipe = StableDiffusionControlNetPipeline.from_pretrained(
            base_model,
            controlnet=self.controlnet,
            torch_dtype=dtype,
            safety_checker=None
        )
        
        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
        self.pipe.scheduler = UniPCMultistepScheduler.from_config(
            self.pipe.scheduler.config
        )
        
        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§
        try:
            self.pipe.enable_model_cpu_offload()
            print("   - Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Model CPU Offload ÙØ¹Ø§Ù„ Ø´Ø¯.")
        except Exception as e:
            print(f"   - âš ï¸ Ø§Ù…Ú©Ø§Ù† ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Model CPU Offload ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {e}")

        try:
            self.pipe.enable_xformers_memory_efficient_attention()
            print("   - Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ xFormers Memory Efficient Attention ÙØ¹Ø§Ù„ Ø´Ø¯.")
        except ImportError:
            print("   - âš ï¸ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ xformers Ù†ØµØ¨ Ù†ÛŒØ³Øª. Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø­Ø§ÙØ¸Ù‡ Ù…Ø±Ø¨ÙˆØ·Ù‡ ØºÛŒØ±ÙØ¹Ø§Ù„ Ø§Ø³Øª.")
        except Exception as e:
            print(f"   - âš ï¸ Ø§Ù…Ú©Ø§Ù† ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ xFormers ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯: {e}")

        self.pipe = self.pipe.to(device)
        
        print("âœ… ControlNet Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
    
    def generate(
        self,
        control_image,
        prompt,
        negative_prompt="",
        num_inference_steps=30,
        guidance_scale=7.5,
        controlnet_conditioning_scale=0.8,
        seed=None,
        num_images=1,
        width=None,
        height=None
    ):
        """
        ØªÙˆÙ„ÛŒØ¯ Ø·Ø±Ø­ ÙØ±Ø´
        
        Args:
            control_image: ØªØµÙˆÛŒØ± Ú©Ù†ØªØ±Ù„ (Ù„Ø¨Ù‡â€ŒÙ‡Ø§)
            prompt: Ù¾Ø±Ø§Ù…Ù¾Øª Ù…Ø«Ø¨Øª
            negative_prompt: Ù¾Ø±Ø§Ù…Ù¾Øª Ù…Ù†ÙÛŒ
            num_inference_steps: ØªØ¹Ø¯Ø§Ø¯ Ù…Ø±Ø§Ø­Ù„
            guidance_scale: Ù…Ù‚ÛŒØ§Ø³ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ
            controlnet_conditioning_scale: Ø´Ø¯Øª Ú©Ù†ØªØ±Ù„
            seed: seed ØªØµØ§Ø¯ÙÛŒ
            num_images: ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ÛŒ
            width: Ø¹Ø±Ø¶ Ø®Ø±ÙˆØ¬ÛŒ
            height: Ø§Ø±ØªÙØ§Ø¹ Ø®Ø±ÙˆØ¬ÛŒ
            
        Returns:
            list: Ù„ÛŒØ³Øª ØªØµØ§ÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡
        """
        if isinstance(control_image, np.ndarray):
            control_image = Image.fromarray(control_image)
        
        # ØªÙ†Ø¸ÛŒÙ… seed
        if seed is not None and seed != -1:
            generator = torch.Generator(device=self.device).manual_seed(seed)
        else:
            generator = None
        
        # ØªÙ†Ø¸ÛŒÙ… Ø§Ø¨Ø¹Ø§Ø¯
        if width is None:
            width = control_image.width
        if height is None:
            height = control_image.height
        
        # Ú¯Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¨Ù‡ Ù…Ø¶Ø±Ø¨ 8
        width = (width // 8) * 8
        height = (height // 8) * 8
        
        print(f"ğŸ¨ ØªÙˆÙ„ÛŒØ¯ Ø·Ø±Ø­ ÙØ±Ø´...")
        print(f"   Ø§Ø¨Ø¹Ø§Ø¯: {width}x{height}")
        print(f"   Steps: {num_inference_steps}")
        print(f"   Guidance Scale: {guidance_scale}")
        print(f"   ControlNet Scale: {controlnet_conditioning_scale}")
        
        # ØªÙˆÙ„ÛŒØ¯
        output = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            image=control_image,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            controlnet_conditioning_scale=controlnet_conditioning_scale,
            generator=generator,
            num_images_per_prompt=num_images,
            width=width,
            height=height
        )
        
        print(f"âœ… {len(output.images)} ØªØµÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯")
        
        return output.images
    
    def generate_batch(
        self,
        control_image,
        prompts_list,
        negative_prompt="",
        **kwargs
    ):
        """
        ØªÙˆÙ„ÛŒØ¯ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ Ø¨Ø§ Ù¾Ø±Ø§Ù…Ù¾Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        
        Args:
            control_image: ØªØµÙˆÛŒØ± Ú©Ù†ØªØ±Ù„
            prompts_list: Ù„ÛŒØ³Øª Ù¾Ø±Ø§Ù…Ù¾Øªâ€ŒÙ‡Ø§
            negative_prompt: Ù¾Ø±Ø§Ù…Ù¾Øª Ù…Ù†ÙÛŒ
            **kwargs: Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
            
        Returns:
            list: Ù„ÛŒØ³Øª ØªÙ…Ø§Ù… ØªØµØ§ÙˆÛŒØ± ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡
        """
        all_images = []
        
        for i, prompt in enumerate(prompts_list):
            print(f"\nğŸ“ Ù¾Ø±Ø§Ù…Ù¾Øª {i+1}/{len(prompts_list)}: {prompt[:50]}...")
            
            images = self.generate(
                control_image=control_image,
                prompt=prompt,
                negative_prompt=negative_prompt,
                **kwargs
            )
            
            all_images.extend(images)
        
        return all_images
    
    def generate_with_variations(
        self,
        control_image,
        base_prompt,
        variations,
        **kwargs
    ):
        """
        ØªÙˆÙ„ÛŒØ¯ Ø¨Ø§ ØªÙ†ÙˆØ¹ Ø¯Ø± Ù¾Ø±Ø§Ù…Ù¾Øª
        
        Args:
            control_image: ØªØµÙˆÛŒØ± Ú©Ù†ØªØ±Ù„
            base_prompt: Ù¾Ø±Ø§Ù…Ù¾Øª Ù¾Ø§ÛŒÙ‡
            variations: Ù„ÛŒØ³Øª ØªØºÛŒÛŒØ±Ø§Øª
            **kwargs: Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
            
        Returns:
            list: Ù„ÛŒØ³Øª ØªØµØ§ÙˆÛŒØ± Ø¨Ø§ ØªÙ†ÙˆØ¹
        """
        prompts = [f"{base_prompt}, {var}" for var in variations]
        return self.generate_batch(control_image, prompts, **kwargs)